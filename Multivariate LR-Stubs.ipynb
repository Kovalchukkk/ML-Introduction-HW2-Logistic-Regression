{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import or define evaluate_classification, plot_decision_boundary, plot_data\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    return accuracy, report, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, y):\n",
    "    # Define the range of values for the features\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "    # Use the classifier to predict the class of each point in the meshgrid\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the decision boundary and the data points\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.8)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title('Decision boundary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, data_columns, target_column):\n",
    "    \"\"\"Load dataset from CSV file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to CSV file.\n",
    "        data_columns (list): List of column names for data.\n",
    "        target_column (str): Name of target column.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing data and target.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    X, y = df[data_columns], df[target_column]\n",
    "    return X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"Logistic Regression Classifier.\"\"\"\n",
    "    def __init__(self, standardize=True, \n",
    "                 learning_rate=0.01, \n",
    "                 max_iter=1000,\n",
    "                 tol=1e-4,\n",
    "                 verbose=False):\n",
    "        \"\"\"Initialize Logistic Regression Classifier.\n",
    "        \n",
    "        Args:\n",
    "            standardize (bool): Whether to standardize the data.\n",
    "            learning_rate (float): Learning rate for gradient descent.\n",
    "            max_iter (int): Maximum number of iterations for gradient descent.\n",
    "            tol (float): Tolerance for gradient descent.\n",
    "            verbose (bool): Whether to print cost at each 100th iteration.\n",
    "        \"\"\"\n",
    "        self.standardize = standardize\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def normalize(self, X):\n",
    "        \"\"\"Normalize the data.\n",
    "        \n",
    "        Args:\n",
    "            X (array): Data to normalize.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Tuple containing normalized data, mean, and standard deviation.\n",
    "        \"\"\"\n",
    "        # TODO: Implement\n",
    "        mean = None\n",
    "        std = None\n",
    "        X_new = None\n",
    "        return X_new, mean, std\n",
    "\n",
    "    def add_intercept(self, X):\n",
    "        \"\"\"Add intercept term to the data.\n",
    "        \n",
    "        Args:\n",
    "            X (array): Data to add intercept term.\n",
    "        \n",
    "        Returns:\n",
    "            array: Data with intercept term.\"\"\"\n",
    "        m = X.shape[0]\n",
    "        ones = np.ones((m, 1))\n",
    "        X_new = np.column_stack((ones, X))\n",
    "        return X_new\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"Sigmoid function.\n",
    "        \n",
    "        Args:\n",
    "            z (array): Input to sigmoid function.\n",
    "            \n",
    "        Returns:\n",
    "            array: Output of sigmoid function.\"\"\"\n",
    "        # TODO: Implement\n",
    "        h = None\n",
    "        return h\n",
    "    \n",
    "    def hypothesis(self, X, theta):\n",
    "        \"\"\"Hypothesis function.\n",
    "        \n",
    "        Args:\n",
    "            X (array): Data.\n",
    "            theta (array): Parameters.\n",
    "        \n",
    "        Returns:\n",
    "            array: Output of hypothesis function.\"\"\"\n",
    "        # TODO: Implement\n",
    "        z = None\n",
    "        return self.sigmoid(z)\n",
    "\n",
    "    def cost_function(self, X, y, theta):\n",
    "        \"\"\"Cost function.\n",
    "        \n",
    "        Args:\n",
    "            X (array): Data.\n",
    "            y (array): Target.\n",
    "            theta (array): Parameters.\n",
    "            \n",
    "        Returns:\n",
    "            float: Cost of hypothesis function.\"\"\"\n",
    "        # TODO: Implement\n",
    "        cost = None\n",
    "        return cost\n",
    "\n",
    "    def gradient(self, X, y, theta):\n",
    "        \"\"\"Gradient of cost function.\n",
    "        \n",
    "        Args:\n",
    "            X (array): Data.\n",
    "            y (array): Target.\n",
    "            theta (array): Parameters.\n",
    "            \n",
    "        Returns:\n",
    "            array: Gradient of cost function.\"\"\"\n",
    "        # TODO: Implement\n",
    "        grad = None\n",
    "        return grad\n",
    "\n",
    "    def gradient_descent(self, X, y, theta):\n",
    "        \"\"\"Gradient descent algorithm.\n",
    "\n",
    "        Args:\n",
    "            X (array): Data.\n",
    "            y (array): Target.\n",
    "            theta (array): Parameters.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Tuple containing parameters and costs.\"\"\"\n",
    "        costs = []\n",
    "        J = self.cost_function(X, y, theta)\n",
    "        costs.append(J)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Iteration 0 Cost: {J}\")\n",
    "\n",
    "        for i in range(1, self.max_iter + 1):\n",
    "            # TODO: Implement\n",
    "            grad = None\n",
    "            theta = None\n",
    "            cost = None\n",
    "            \n",
    "            costs.append(cost)\n",
    "\n",
    "            if i % 100 == 0 and self.verbose:\n",
    "                print(f\"Iteration {i} Cost: {cost}\")\n",
    "\n",
    "            if np.abs(costs[i] - costs[i - 1]) < self.tol:\n",
    "                print(f\"Converged at iteration {i}\")\n",
    "                break\n",
    "\n",
    "        return theta, costs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "\n",
    "        Args:\n",
    "            X (array): Data.\n",
    "            y (array): Target.\"\"\"\n",
    "        if self.standardize:\n",
    "            X_new, self.mean, self.std = self.normalize(X)\n",
    "        X_new = self.add_intercept(X_new)\n",
    "\n",
    "        self.theta = np.zeros(X_new.shape[1])\n",
    "        self.theta, self.costs = self.gradient_descent(X_new, y, self.theta)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the target.\n",
    "\n",
    "        Args:\n",
    "            X (array): Data.\n",
    "\n",
    "        Returns:\n",
    "            array: Predicted target.\"\"\"\n",
    "        # TODO: Implement\n",
    "        if self.standardize:\n",
    "            X_new = None\n",
    "        X_new = None\n",
    "\n",
    "        y_pred = None\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict the probability of target.\n",
    "        \n",
    "        Args:\n",
    "            X (array): Data.\n",
    "        \n",
    "        Returns:\n",
    "            array: Predicted probability of target.\"\"\"\n",
    "        # TODO: Implement\n",
    "        if self.standardize:\n",
    "            X_new = None\n",
    "        X_new = None\n",
    "\n",
    "        h = None\n",
    "        return np.column_stack((1-h, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m X, y \u001b[39m=\u001b[39m make_classification(n_samples \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m, n_classes \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, n_features \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, \n\u001b[0;32m      2\u001b[0m                            n_informative\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, n_redundant\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, random_state \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m,\n\u001b[0;32m      3\u001b[0m                            flip_y\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, class_sep\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plot_data(X, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_data' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples = 200, n_classes = 2, n_features = 2, \n",
    "                           n_informative=2, n_redundant=0, random_state = 42,\n",
    "                           flip_y=0.02, class_sep=0.8)\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(standardize=True, learning_rate=0.01, max_iter=1000, tol=1e-4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, report, confusion = evaluate_classification(y_test, y_test_pred)\n",
    "print(f\"Accuracy: \\n{accuracy}\")\n",
    "print(f\"Report: \\n{report}\")\n",
    "print(f\"Confusion: \\n{confusion}\")\n",
    "plot_decision_boundary(lr, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=500, noise=0.2, random_state=42)\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "lr = LogisticRegression(standardize=True, learning_rate=0.01, max_iter=1000, tol=1e-4, verbose=True)\n",
    "lr.fit(X_train, y_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "accuracy, report, confusion = evaluate_classification(y_test, y_test_pred)\n",
    "print(f\"Accuracy: \\n{accuracy}\")\n",
    "print(f\"Report: \\n{report}\")\n",
    "print(f\"Confusion: \\n{confusion}\")\n",
    "plot_decision_boundary(lr, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the above LogisticRegression class on datasets sats.csv and tests.csv. Consider using polynomial features when applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = [\"exam1\", \"exam2\"]\n",
    "target_column = \"submitted\"\n",
    "X, y = load_dataset('sats.csv', data_columns, target_column)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(standardize=True, learning_rate=0.01, max_iter=1000, tol=1e-4, verbose=True)\n",
    "lr.fit(X_train, y_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "accuracy, report, confusion = evaluate_classification(y_test, y_test_pred)\n",
    "print(f\"Accuracy: \\n{accuracy}\")\n",
    "print(f\"Report: \\n{report}\")\n",
    "print(f\"Confusion: \\n{confusion}\")\n",
    "plot_decision_boundary(lr, X_test, y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8df173b65e7d4911fe3a36523b49f8a295b4f9ef02cf106a3159aa92aa441c3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
